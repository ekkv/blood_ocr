{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f787766",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Predicting Module.\"\"\"\n",
    "\n",
    "from collections import OrderedDict\n",
    "from typing import List\n",
    "\n",
    "import click\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from albumentations import Compose\n",
    "import albumentations as album\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square, convex_hull_image\n",
    "from skimage.transform import resize\n",
    "from skimage.util import invert\n",
    "\n",
    "from tablenet import TableNetModule\n",
    "\n",
    "\n",
    "class Predict:\n",
    "    \"\"\"Predict images using pre-trained model.\"\"\"\n",
    "\n",
    "    def __init__(self, checkpoint_path: str, transforms: Compose, threshold: float = 0.5, per: float = 0.005):\n",
    "        \"\"\"Predict images using pre-trained TableNet model.\n",
    "\n",
    "        Args:\n",
    "            checkpoint_path (str): model weights path.\n",
    "            transforms (Optional[Compose]): Compose object from albumentations used for pre-processing.\n",
    "            threshold (float): threshold to consider the value as correctly classified.\n",
    "            per (float): Minimum area for tables and columns to be considered.\n",
    "        \"\"\"\n",
    "        self.transforms = transforms\n",
    "        self.threshold = threshold\n",
    "        self.per = per\n",
    "\n",
    "        self.model = TableNetModule.load_from_checkpoint(checkpoint_path)\n",
    "        self.model.eval()\n",
    "        self.model.requires_grad_(False)\n",
    "        self.reader = easyocr.Reader(['ru'])\n",
    "\n",
    "    def predict(self, image: Image) -> List[pd.DataFrame]:\n",
    "        \"\"\"Predict a image table values.\n",
    "\n",
    "        Args:\n",
    "            image (Image): PIL.Image to\n",
    "\n",
    "        Returns (List[pd.DataFrame]): Tables in pandas DataFrame format.\n",
    "        \"\"\"\n",
    "        processed_image = self.transforms(image=np.array(image))[\"image\"]\n",
    "\n",
    "        table_mask, column_mask = self.model.forward(processed_image.unsqueeze(0))\n",
    "\n",
    "        table_mask = self._apply_threshold(table_mask)\n",
    "        column_mask = self._apply_threshold(column_mask)\n",
    "\n",
    "        segmented_tables = self._process_tables(self._segment_image(table_mask))\n",
    "\n",
    "        tables = []\n",
    "        for table in segmented_tables:\n",
    "            segmented_columns = self._process_columns(self._segment_image(column_mask * table))\n",
    "            if segmented_columns:\n",
    "                cols = []\n",
    "                for column in segmented_columns.values():\n",
    "                    cols.append(self._column_to_dataframe(column, image, self.reader))\n",
    "                tables.append(pd.concat(cols, ignore_index=True, axis=1))\n",
    "        return tables\n",
    "\n",
    "    def _apply_threshold(self, mask):\n",
    "        mask = mask.squeeze(0).squeeze(0).numpy() > self.threshold\n",
    "        return mask.astype(int)\n",
    "\n",
    "    def _process_tables(self, segmented_tables):\n",
    "        width, height = segmented_tables.shape\n",
    "        tables = []\n",
    "        for i in np.unique(segmented_tables)[1:]:\n",
    "            table = np.where(segmented_tables == i, 1, 0)\n",
    "            if table.sum() > height * width * self.per:\n",
    "                tables.append(convex_hull_image(table))\n",
    "\n",
    "        return tables\n",
    "\n",
    "    def _process_columns(self, segmented_columns):\n",
    "        width, height = segmented_columns.shape\n",
    "        cols = {}\n",
    "        for j in np.unique(segmented_columns)[1:]:\n",
    "            column = np.where(segmented_columns == j, 1, 0)\n",
    "            column = column.astype(int)\n",
    "\n",
    "            if column.sum() > width * height * self.per:\n",
    "                position = regionprops(column)[0].centroid[1]\n",
    "                cols[position] = column\n",
    "        return OrderedDict(sorted(cols.items()))\n",
    "\n",
    "    @staticmethod\n",
    "    def _segment_image(image):\n",
    "        thresh = threshold_otsu(image)\n",
    "        bw = closing(image > thresh, square(2))\n",
    "        cleared = clear_border(bw)\n",
    "        label_image = label(cleared)\n",
    "        return label_image\n",
    "\n",
    "    @staticmethod\n",
    "    def _column_to_dataframe(column, image, reader):\n",
    "        width, height = image.size\n",
    "        column = resize(np.expand_dims(column, axis=2), (height, width), preserve_range=True) > 0.01\n",
    "\n",
    "        crop = column * image\n",
    "        white = np.ones(column.shape) * invert(column) * 255\n",
    "        crop = crop + white\n",
    "        ocr = reader.readtext(crop.astype(np.uint8))\n",
    "        return pd.DataFrame({\"col\": [value[1] for value in ocr if len(value) > 0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33623e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверка пар, сбор списка пар\n",
    "rootdir = \"./datasets/405/\"\n",
    "regex_find = re.compile('(.*csv$)|(.*jpg$)')\n",
    "jpg_list = []\n",
    "csv_list = []\n",
    "\n",
    "for root, dirs, files in os.walk(rootdir):\n",
    "    for file in files:\n",
    "        if regex_find.match(file):\n",
    "            temp = os.path.splitext(file)\n",
    "            if temp[1] == '.jpg':\n",
    "                name = temp[0] + temp[1]\n",
    "                clean_name = temp[0].strip() + temp[1]\n",
    "                if name != clean_name:\n",
    "                    os.rename(rootdir+'/'+name, rootdir+'/'+clean_name) # убираем лишние пробелы в названиях фото\n",
    "                jpg_list.append(temp[0])\n",
    "            else: csv_list.append(temp[0])\n",
    "\n",
    "for x in jpg_list:\n",
    "    if x not in csv_list:\n",
    "        print(f'Отсутствует csv для {x}.jpg')\n",
    "\n",
    "for x in csv_list:\n",
    "    if x not in jpg_list:\n",
    "        print(f'Отсутствует jpg для {x}.csv')\n",
    "\n",
    "pairs_list = list(set(jpg_list) & set(csv_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb630324",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights = \"./tablenet/ocr_model.ckpt\"\n",
    "\n",
    "transforms = album.Compose([\n",
    "    album.Resize(896, 896, always_apply=True),\n",
    "    album.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "for x in pairs_list:\n",
    "    try:\n",
    "        pred = Predict(model_weights, transforms)\n",
    "        image_path = './datasets/405/'+x+'.jpg'\n",
    "        image = Image.open(image_path)\n",
    "        print(pred.predict(image))\n",
    "    except: print(x, 'не обработан')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62c3f47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
